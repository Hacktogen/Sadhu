#!/usr/bin/env python3
"""Plot the live microphone signal(s) with matplotlib.

Matplotlib and NumPy have to be installed.

"""
import random
import argparse
import queue
import pygame
from playsound import playsound
import sys
import cv2 ,time
from datetime import datetime
import tensorflow.keras as keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D , MaxPooling2D
from keras.layers import Activation,Dropout,Flatten ,Dense
from keras import backend as K
from keras.preprocessing import image
from matplotlib.animation import FuncAnimation
import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
global video
import random
import uuid


def int_or_str(text):
    """Helper function for argument parsing."""
    try:
        return int(text)
    except ValueError:
        return text


parser = argparse.ArgumentParser(add_help=False)
parser.add_argument(
    '-l', '--list-devices', action='store_true',
    help='show list of audio devices and exit')
args, remaining = parser.parse_known_args()
if args.list_devices:
    print(sd.query_devices())
    parser.exit(0)
parser = argparse.ArgumentParser(
    description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    parents=[parser])
parser.add_argument(
    'channels', type=int, default=[1], nargs='*', metavar='CHANNEL',
    help='input channels to plot (default: the first)')
parser.add_argument(
    '-d', '--device', type=int_or_str,
    help='input device (numeric ID or substring)')
parser.add_argument(
    '-w', '--window', type=float, default=200, metavar='DURATION',
    help='visible time slot (default: %(default)s ms)')
parser.add_argument(
    '-i', '--interval', type=float, default=30,
    help='minimum time between plot updates (default: %(default)s ms)')
parser.add_argument(
    '-b', '--blocksize', type=int, help='block size (in samples)')
parser.add_argument(
    '-r', '--samplerate', type=float, help='sampling rate of audio device')
parser.add_argument(
    '-n', '--downsample', type=int, default=10, metavar='N',
    help='display every Nth sample (default: %(default)s)')
args = parser.parse_args(remaining)
if any(c < 1 for c in args.channels):
    parser.error('argument CHANNEL: must be >= 1')
mapping = [c - 1 for c in args.channels]  # Channel numbers start with 1
q = queue.Queue()


def audio_callback(indata, frames, time, status):
    """This is called (from a separate thread) for each audio block."""
    if status:
        print(status, file=sys.stderr)
    # Fancy indexing with mapping creates a (necessary!) copy:
    q.put(indata[::args.downsample, mapping])


def update_plot(frame):
    """This is called by matplotlib for each plot update.

    Typically, audio callbacks happen more frequently than plot updates,
    therefore the queue tends to contain multiple blocks of audio data.

    """
    global plotdata
    mc=[]
    model=keras.models.load_model('Model_Tabla10_model.h5')
    while True:

        try:
            data = q.get_nowait()
        except queue.Empty:
            break
        shift = len(data)
        plotdata = np.roll(plotdata, -shift, axis=0)
        plotdata[-shift:, :] = data
        x=abs(plotdata * 10000)

    for column, line in enumerate(lines):

        line.set_ydata(plotdata[:, column])

        if(x[column]>20):
                cap = cv2.VideoCapture(0)

            # try:
                print("lol")
                # an error comes if it does not find anything in window as it cannot find contour of max area
                # therefore this try error statement

                ret, frame = cap.read()
                # frame = cv2.flip(frame, 1)
                kernel = np.ones((3, 3), np.uint8)

                # define region of interest
                roi = frame[100:600, 100:600]

                cv2.rectangle(frame, (100, 500), (300, 500), (0, 255, 0), 0)
                hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

                # define range of skin color in HSV
                lower_skin = np.array([0, 20, 70], dtype=np.uint8)
                upper_skin = np.array([20, 150, 150], dtype=np.uint8)

                # extract skin colur imagw
                mask = cv2.inRange(hsv, lower_skin, upper_skin)

                # extrapolate the hand to fill dark spots within
                mask = cv2.dilate(mask, kernel, iterations=4)

                # blur the image
                mask = cv2.GaussianBlur(mask, (5, 5), 100)
                mask = cv2.resize(mask, (100, 100))
                # show the windows
                cv2.imshow('mask', mask)
                cv2.imshow('frame', frame)
                frame23 = cv2.resize(mask, (100, 100))
                frame23=np.expand_dims(frame23,axis=0)
                frame23=np.expand_dims(frame23,axis=-1)
                frame23=frame23.reshape(1,100,100,1)
                print(frame23.shape)
                note=(model.predict(frame23).argmax())
                note1 = (model.predict(frame23))
                print(note1[0:4])

                if (note == 1):
                    print("Te")
                    playsound('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
                    # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
                    # pygame.mixer.music.set_volume()
                    # pygame.mixer.music.play()

                if (note == 0):
                    print("Ta")
                    playsound('C:/Users/ADMIN/Desktop/Rotunda/Ta_Sound.wav')
                    # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Ta_Sound.wav')
                    # pygame.mixer.music.set_volume()
                    # pygame.mixer.music.play()

                if (note == 2):
                    print("Tin")
                    playsound('C:/Users/ADMIN/Desktop/Rotunda/Tin_Sound.wav')
                    # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
                    # pygame.mixer.music.set_volume()
                    # pygame.mixer.music.play()

                if (note == 3):
                    print("Tun")
                    playsound('C:/Users/ADMIN/Desktop/Rotunda/Tun_Sound.wav')

                # cv2.destroyAllWindows()
                # cap.release()


            # except:
            #     pass
            #     ret, frame = cap.read()
            #     # frame = cv2.flip(frame, 1)
            #     kernel = np.ones((3, 3), np.uint8)
            #
            #     # define region of interest
            #     roi = frame[100:600, 100:600]
            #
            #     cv2.rectangle(frame, (100, 500), (300, 500), (0, 255, 0), 0)
            #     hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
            #
            #     # define range of skin color in HSV
            #     lower_skin = np.array([0, 20, 70], dtype=np.uint8)
            #     upper_skin = np.array([20, 150, 150], dtype=np.uint8)
            #
            #     # extract skin colur imagw
            #     mask = cv2.inRange(hsv, lower_skin, upper_skin)
            #
            #     # extrapolate the hand to fill dark spots within
            #     mask = cv2.dilate(mask, kernel, iterations=4)
            #
            #     # blur the image
            #     mask = cv2.GaussianBlur(mask, (5, 5), 100)
            #     mask = cv2.resize(mask, (100, 100))
            #     # show the windows
            #     cv2.imshow('mask', mask)
            #     cv2.imshow('frame', frame)
            #     frame23 = cv2.resize(mask, (100, 100))
            #     print(frame23.shape)
            #     frame23 = np.expand_dims(frame, axis=0)
            #     frame23 = np.expand_dims(frame, axis=-1)
            #     frame23 = frame23.reshape(1, 100, 100, 1)
            #     print(frame.shape)
            #     note = (model.predict(frame23).argmax())
            #     note1 = (model.predict(frame23))
            #     print(note1[0:4])
            #
            #     if (note == 1):
            #         print("Te")
            #         playsound('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
            #         # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
            #         # pygame.mixer.music.set_volume()
            #         # pygame.mixer.music.play()
            #
            #     if (note == 0):
            #         print("Ta")
            #         playsound('C:/Users/ADMIN/Desktop/Rotunda/Ta_Sound.wav')
            #         # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Ta_Sound.wav')
            #         # pygame.mixer.music.set_volume()
            #         # pygame.mixer.music.play()
            #
            #     if (note == 2):
            #         print("Tin")
            #         playsound('C:/Users/ADMIN/Desktop/Rotunda/Tin_Sound.wav')
            #         # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Te_Sound.wav')
            #         # pygame.mixer.music.set_volume()
            #         # pygame.mixer.music.play()
            #
            #     if (note == 3):
            #         print("Tun")
            #         playsound('C:/Users/ADMIN/Desktop/Rotunda/Tun_Sound.wav')
            #
            #     cv2.destroyAllWindows()
            #     cap.release()
            #
            #     k = cv2.waitKey(5) & 0xFF
            #     if k == 27:
            #         break
            #

        return lines
        cv2.destroyAllWindows()
        cap.release()

        # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Tin_Sound.wav')
            # pygame.mixer.music.set_volume()
            # pygame.mixer.music.play()

            # if (note == 4):
            #    playsound('C:/Users/ADMIN/Desktop/Rotunda/Tun_Sound.wav')
            #    # pygame.mixer.music.load('C:/Users/ADMIN/Desktop/Rotunda/Tun_Sound.wav')
            #    # pygame.mixer.music.set_volume()
            #    # pygame.mixer.music.play()
            #    print("Tun")

    return lines
    cv2.destroyAllWindows()
    cap.release()








try:
    if args.samplerate is None:
        device_info = sd.query_devices(args.device, 'input')
        args.samplerate = device_info['default_samplerate']

    length = int(args.window * args.samplerate / (1000 * args.downsample))
    plotdata = np.zeros((length, len(args.channels)))

    fig, ax = plt.subplots()
    lines = ax.plot(plotdata)
    if len(args.channels) > 1:
        ax.legend(['channel {}'.format(c) for c in args.channels],
                  loc='lower left', ncol=len(args.channels))
    ax.axis((0, len(plotdata), -1, 1))
    ax.set_yticks([0])
    ax.yaxis.grid(True)
    ax.tick_params(bottom=False, top=False, labelbottom=False,
                   right=False, left=False, labelleft=False)
    fig.tight_layout(pad=0)

    stream = sd.InputStream(
        device=args.device, channels=max(args.channels),
        samplerate=args.samplerate, callback=audio_callback)
    ani = FuncAnimation(fig, update_plot, interval=args.interval, blit=True)
    with stream:
        plt.show()

except Exception as e:
    parser.exit(type(e).__name__ + ': ' + str(e))
