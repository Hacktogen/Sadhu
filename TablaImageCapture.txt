#!/usr/bin/env python3
"""Plot the live microphone signal(s) with matplotlib.

Matplotlib and NumPy have to be installed.

"""
import random
import argparse
import queue
import sys
import cv2 ,time
from datetime import datetime
import tensorflow.keras as keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D , MaxPooling2D
from keras.layers import Activation,Dropout,Flatten ,Dense
from keras import backend as K
from keras.preprocessing import image
from matplotlib.animation import FuncAnimation
import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
global video
import random
import uuid

cap = cv2.VideoCapture(0)
a=0
b=0
c=300
d=300
r = 0
t = 20
y = 70
f = 30
g = 150
h = 150
while (1):

    try:  # an error comes if it does not find anything in window as it cannot find contour of max area
        # therefore this try error statement

        ret, frame = cap.read()
        # frame = cv2.flip(frame, 1)
        kernel = np.ones((3, 3), np.uint8)
        # define region of interest
        cv2.rectangle(frame, (a, b), (c, d), (0,255, 0), 2)
        # if cv2.waitKey(10) & 0xFF==ord('x'):
        #     c=c+5
        #     d=d+5
        # if cv2.waitKey(10) & 0xFF==ord('c'):
        #     c=c-10
        #     d=d-10
        if cv2.waitKey(10) & 0xFF==ord('s'):
            b=b+10
            d=d+10
        if cv2.waitKey(10) & 0xFF==ord('w'):
            b=b-10
            d=d-10
        if cv2.waitKey(10) & 0xFF==ord('d'):
            a=a+10
            c=c+10
        if cv2.waitKey(10) & 0xFF==ord('a'):
            c=c-10
            a=a-10
        roi = frame[b:d,a:c]
        cv2.imshow('roi',roi)
        # roi1 = cv2.resize(roi, (100, 100))
        # cv2.imshow('roi1', roi1)
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        if cv2.waitKey(10) & 0xFF == ord('u'):
            r=r+10
            # d = d + 10
        if cv2.waitKey(10) & 0xFF == ord('i'):
            t=t+10
            # d = d - 10
        if cv2.waitKey(10) & 0xFF == ord('o'):
            y=y+10
        if cv2.waitKey(10) & 0xFF == ord('p'):
            r=r-10
            # d = d + 10
        if cv2.waitKey(10) & 0xFF == ord('['):
            t=t-10
            # d = d - 10
        if cv2.waitKey(10) & 0xFF == ord(']'):
            y=y-10
        if cv2.waitKey(10) & 0xFF == ord('3'):
            r = 0
            t = 20
            y = 70

        if cv2.waitKey(10) & 0xFF == ord('v'):
            f=f+10
            # d = d + 10
        if cv2.waitKey(10) & 0xFF == ord('b'):
            g=g+10
            # d = d - 10
        if cv2.waitKey(10) & 0xFF == ord('n'):
            h=h+10
        if cv2.waitKey(10) & 0xFF == ord('m'):
            f=f-10
            # d = d + 10
        if cv2.waitKey(10) & 0xFF == ord(','):
            g=g-10
            # d = d - 10
        if cv2.waitKey(10) & 0xFF == ord('.'):
            h=h-10
        if cv2.waitKey(10) & 0xFF == ord('4'):
            f = 30
            g = 150
            h = 150

        lower_skin = np.array([r, t, y], dtype=np.uint8)
        upper_skin = np.array([f, g, h], dtype=np.uint8)
        # lower_skin = np.array([0, 20, 70], dtype=np.uint8)
        # upper_skin = np.array([30, 150, 150], dtype=np.uint8)
        mask = cv2.inRange(hsv, lower_skin, upper_skin)
        mask = cv2.dilate(mask, kernel, iterations=1)
        cv2.imshow('mask', mask)
        cv2.imshow('frame', frame)
        # mask = cv2.resize(mask, (100, 100))
        # cv2.imshow('maskreshape', mask)

    except:
        pass
    if cv2.waitKey(10) & 0xFF == ord('k'):
        cv2.destroyAllWindows()
        cap.release()
        break



def int_or_str(text):
    """Helper function for argument parsing."""
    try:
        return int(text)
    except ValueError:
        return text


parser = argparse.ArgumentParser(add_help=False)
parser.add_argument(
    '-l', '--list-devices', action='store_true',
    help='show list of audio devices and exit')
args, remaining = parser.parse_known_args()
if args.list_devices:
    print(sd.query_devices())
    parser.exit(0)
parser = argparse.ArgumentParser(
    description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    parents=[parser])
parser.add_argument(
    'channels', type=int, default=[1], nargs='*', metavar='CHANNEL',
    help='input channels to plot (default: the first)')
parser.add_argument(
    '-d', '--device', type=int_or_str,
    help='input device (numeric ID or substring)')
parser.add_argument(
    '-w', '--window', type=float, default=200, metavar='DURATION',
    help='visible time slot (default: %(default)s ms)')
parser.add_argument(
    '-i', '--interval', type=float, default=30,
    help='minimum time between plot updates (default: %(default)s ms)')
parser.add_argument(
    '-b', '--blocksize', type=int, help='block size (in samples)')
parser.add_argument(
    '-r', '--samplerate', type=float, help='sampling rate of audio device')
parser.add_argument(
    '-n', '--downsample', type=int, default=10, metavar='N',
    help='display every Nth sample (default: %(default)s)')
args = parser.parse_args(remaining)
if any(c < 1 for c in args.channels):
    parser.error('argument CHANNEL: must be >= 1')
mapping = [c - 1 for c in args.channels]  # Channel numbers start with 1
q = queue.Queue()


def audio_callback(indata, frames, time, status):
    """This is called (from a separate thread) for each audio block."""
    if status:
        print(status, file=sys.stderr)
    # Fancy indexing with mapping creates a (necessary!) copy:
    q.put(indata[::args.downsample, mapping])

print(r)
print(t)
print(y)
print(f)
print(g)
print(h)


def update_plot(frame):
    """This is called by matplotlib for each plot update.

    Typically, audio callbacks happen more frequently than plot updates,
    therefore the queue tends to contain multiple blocks of audio data.

    """
    global plotdata
    while True:

        try:
            data = q.get_nowait()
        except queue.Empty:
            break
        shift = len(data)
        plotdata = np.roll(plotdata, -shift, axis=0)
        plotdata[-shift:, :] = data
        x=abs(plotdata * 10000)
    print (x)
    for column, line in enumerate(lines):

        line.set_ydata(plotdata[:, column])
        if(x[column]>500):
                cap = cv2.VideoCapture(0)
                ret, frame = cap.read()
                roi = frame[b:d,a:c]
                hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
                lower_skin = np.array([r,t,y], dtype=np.uint8)
                upper_skin = np.array([f,g,h], dtype=np.uint8)
                mask = cv2.inRange(hsv, lower_skin, upper_skin)
                mask = cv2.dilate(mask, kernel, iterations=1)
                value=random.random()
                outfile =('C://Users/ADMIN/Desktop/SohanYo_R%f.jpg'%value)
                cv2.imwrite(outfile,frame)
                cv2.imshow('Caps',frame)
                cv2.waitKey(600)
                cv2.destroyAllWindows()
                cap.release()
                # video.release()
                # cv2.destroyAllWindows()


    return lines



try:
    if args.samplerate is None:
        device_info = sd.query_devices(args.device, 'input')
        args.samplerate = device_info['default_samplerate']

    length = int(args.window * args.samplerate / (1000 * args.downsample))
    plotdata = np.zeros((length, len(args.channels)))

    fig, ax = plt.subplots()
    lines = ax.plot(plotdata)
    if len(args.channels) > 1:
        ax.legend(['channel {}'.format(c) for c in args.channels],
                  loc='lower left', ncol=len(args.channels))
    ax.axis((0, len(plotdata), -1, 1))
    ax.set_yticks([0])
    ax.yaxis.grid(True)
    ax.tick_params(bottom=False, top=False, labelbottom=False,
                   right=False, left=False, labelleft=False)
    fig.tight_layout(pad=0)

    stream = sd.InputStream(
        device=args.device, channels=max(args.channels),
        samplerate=args.samplerate, callback=audio_callback)
    ani = FuncAnimation(fig, update_plot, interval=args.interval, blit=True)
    with stream:
        plt.show()

except Exception as e:
    parser.exit(type(e).__name__ + ': ' + str(e))
